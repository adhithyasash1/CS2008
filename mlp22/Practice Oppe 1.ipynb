{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPENzvWGUoj1om0tkirvugZ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["### Access the dataset from here :\n","\n","https://drive.google.com/file/d/1XztaPmhMMhBoEp7XuyDGS5Il_kLUlEEl/view?usp=sharing"],"metadata":{"id":"5YVDPF_SKyQU"}},{"cell_type":"markdown","source":["### Notes:\n","* This exam consists of a Regression problem.  \n","* The target feature is 'cltv'.\n","* Random state should be taken as 42 wherever applicable."],"metadata":{"id":"UwkYDkX3uuR7"}},{"cell_type":"markdown","source":["# Metadata\n","\n","1. id-Unique identifier of a customer  \n","2. gender-Gender of the customer   \n","3. area-Area of the customer   \n","4. qualification-Highest Qualification of the customer  \n","5. income-Income earned in a year (in rupees).   \n","6. marital_status- 0:Single, 1: Married\n","7. vintage-No. of years since the first policy date.  \n","8. claim_amount-Total Amount Claimed by the customer (in rupees)\n","9. num_policies-Total no. of policies issued by the customer\n","10. policy-Active policy of the customer\n","11. type_of_policy-Type of active policy\n","12. cltv- Customer life time value. It is the total amount of money a customer is expected to spend with your business, or on your products, during the lifetime of an average business relationship. [TARGET]"],"metadata":{"id":"1KdRF2l1upLN"}},{"cell_type":"markdown","source":["Q.2 [Marks: 2] How many total number of features (excluding target variable) are there in the dataset?\n","Options\n","\n","(a) 1000\n","\n","(b) 11\n","\n","(c) 12\n","\n","(d) 10"],"metadata":{"id":"oWTaKRq3r2a8"}},{"cell_type":"markdown","source":["## Q.3 [Marks: 2] What are the unique values of feature `Types of Policy` in the dataset?\n","\n","A) ['Bronze', 'Gold']\n","\n","B) ['Gold', 'Silver']\n","\n","C) ['Platinum', 'Gold', 'Silver', 'Bronze]\n","\n","D) ['Platinum', 'Gold', 'Silver']\n"],"metadata":{"id":"hPaxHB-ar3Uo"}},{"cell_type":"markdown","source":["## Q.4 [Marks: 3] Which of the following columns have categorical data?[MSQ]\n","\n","A) income\n","\n","B) id\n","\n","C) area\n","\n","D) claim_amount\n","\n","E) qualification"],"metadata":{"id":"ifUUdNYxsA4k"}},{"cell_type":"markdown","source":["## Q5.[Marks: 4] Plot the `heatmap` and mark the pair which has the highest positive correlation value. [MCQ]\n","\n","A) claim_amount & income\n","\n","B) income & cltv\n","\n","C) vintage & income.\n","\n","D) claim_amount & cltv."],"metadata":{"id":"i9tuLLOqsg98"}},{"cell_type":"markdown","source":["## Q6 [marks: 2] Which of the following features have `missing` values?[MSQ]\n","\n","Options:\n","\n","A) gender\n","\n","B) area\n","\n","C) qualification\n","\n","D) income\n","\n","E) claim_amount\n","\n","F) policy"],"metadata":{"id":"x7cJbeFsskT1"}},{"cell_type":"markdown","source":["##Q7 [Marks = 4] Break the dataset into features(`X`) and label (`y`), where the column `cltv` goes to `y` and the rest of the columns go to `X`. Enter the avg value of `cltv` column? [NAT]\n"],"metadata":{"id":"AM2i3APmsoOp"}},{"cell_type":"markdown","source":["# Q8 [Marks : 3] Split the dataset into training and test dataset using `train_test_split` into `70:30` ratio while keeping random_state =42. What is the shape of the training set (X_train) ? [MCQ]\n","\n","Ans:\n","\n","A) (4379, 11)\n","\n","B) (4392, 13)\n","\n","C) (4340, 11)\n","\n","D) (4379, 15)"],"metadata":{"id":"GdI9po-Dsybi"}},{"cell_type":"markdown","source":["## Q9 [Mark 2] Drop(remove) `id` column from train and test data because it is not useful in model training. Now how many feature columns are remaining in the training dataset? [NAT]"],"metadata":{"id":"2YC7SujBs21a"}},{"cell_type":"markdown","source":["##Q10 [Marks2] Compute and write median of the `income` column of X_train while ignoring the missing values. Replace all NaN values in the income column of X_train and X_test by the median  computed from the X_train (upto two decimal). [NAT]."],"metadata":{"id":"pofQhio-s5gR"}},{"cell_type":"markdown","source":["##Q11 [2 Marks] Which is the most frequent value in the `policy` column of X_train? Replace all NaN value in `policy` column of X_train and X_test by most frequent value in X_train [MCQ]\n","\n","a) 'A'\n","\n","b) 'B'\n","\n","c) 'C'\n","\n","d) None of the above"],"metadata":{"id":"LzYMUbQEs_Pr"}},{"cell_type":"markdown","source":["##Q12 [2 Marks] Which is the most frequent value in the `area` column of X_train? Replace all NaN value in `area` column of X_train and X_test by most frequent value from X_train [MCQ]\n","\n","a) 'Urban'\n","\n","b) 'Rural'\n","\n","c) 'Semi-Urban'\n","\n","d) None of the above"],"metadata":{"id":"ACU-ysDBtCfm"}},{"cell_type":"markdown","source":["## Q13[2 Marks] Replace all NaN value in claim_amount column of X_train and X_test by 0 (Zero). After Replacing NAN values from claim_amount column what is the standard deviation of claim_amount column in X_train. (correct upto two decimal places) [NAT]"],"metadata":{"id":"Dltyhgt2tHFU"}},{"cell_type":"markdown","source":["#Q14 [Marks: 4] Apply `MinMaxScaler` on `income` column of X_train. Compute and write median of `income` column? (correct Upto 2 decimal)[NAT]"],"metadata":{"id":"ZTJ6FNLotL5L"}},{"cell_type":"markdown","source":["# Apply preprocessing on features of X_train and X_test dataset.\n","\n","## For Categorical Features\n","\n","* Apply OneHotEncoding from `sklearn` library on all categorical features(object columns). Do Encoding in the order of following list\n","\n","* ['gender', 'area','qualification','marital_status', 'num_policies', 'policy', 'type_of_policy']\n","\n","Lets call the transformed caterical feature matrix $X_1$\n","\n","## For Numerical Features\n","\n","apply MinMaxScaler and transform the dataset. Do scaling in the order of following list\n","\n","Numerical Features =  [ 'income', 'vintage', 'claim_amount' ]\n","\n","\n","Lets call the transformed numerical feature matrix $X_2$\n","\n","### concatenate(One Hot Encoded Features, Scaled Numerical Features)\n","\n","After combining transformed categorical feature($X_1$) matrix and transformed numerical feature matrix ($X_2$) (side by side in that order), the output will be $X=[X_1 X_2]$\n","\n","## Hints\n","* Apply ColumnTransformer to encode categorical columns scaling on numerical columns with required preprocessor\n","\n","* Another way is to separately encode all categorical columns and scale numerical columns and do concatenate (`hstack`) both. keep categorical columns in front of numerical while concatenating.\n","\n","\n","The transformed (as desribed by above steps) X_train and X_test, should be considered as X_train and X_test henceforth.\n"],"metadata":{"id":"jSJWsm6XtaVR"}},{"cell_type":"markdown","source":["## Q15 [Marks:10] How many features you will get after preprocessing? [MCQ]\n","\n","[Options]\n","\n","A) 13\n","\n","B) 20\n","\n","C) 25\n","\n","D) 01"],"metadata":{"id":"8bMmm5Nh6Ux1"}},{"cell_type":"markdown","source":["## Q16 [Marks 5 ] Apply `SequentialFeatureSelector` transformer with direction= 'forward' with `LinearRegression()` estimator and select 5 features by fitting to the X_train and y_train.\n","\n","* Use cv = KFold(n_splits=5,random_state=42,shuffle=True) in SequentialFeatureSelector.\n","\n","## Which of the following options represents the correct integer index of the selected features list?\n","\n","\n","A) [ 6  9 12 13 19]\n","\n","B) [ 3  6  9 13 19]\n","\n","C) [ 8  9 12 14 19]\n","\n","D) [ 1  2  9 13 19]\n","\n","E) [ 3  7 10 13 19]\n"],"metadata":{"id":"NOJilIVp6Zi4"}},{"cell_type":"markdown","source":["## Q17 [Marks: 3] Apply `LinearRegression` on the trainig set(`X_train` and `y_train`). What is the `R2 score` on the test set(`X_test` and `y_test`). ( Upto 4 digits after decimal points) [NAT]\n"],"metadata":{"id":"aeAqlJbI6tHl"}},{"cell_type":"markdown","source":["ANS:- V1: 0.1432 (Range: 0.1410 - 0.1450)"],"metadata":{"id":"WX55TK5r_yqy"}},{"cell_type":"markdown","source":["## Q18 [Marks: 6]Using the `LinearRegression` model, compute the `cross-validation scores` for `5 splits` on training data (X_train and y_train) using `cross_val_score`.Enter the maximum value of `ùëÖ2 score` ( Upto 4 digits after decimal points) obtained.[NAT]\n","\n","* Use cv = KFold(n_splits=5,random_state=42,shuffle=True) in SequentialFeatureSelector.\n","\n","(Hint: By default cross_val_score uses LinearRegression's scoring metric, which is  ùëÖ2 score.)"],"metadata":{"id":"yvieiOk06wZO"}},{"cell_type":"markdown","source":["V1: 0.1815 (Range: 0.1790-0.1845)"],"metadata":{"id":"W0GZbM4DCIBK"}},{"cell_type":"markdown","source":["Q19 [Marks :5]Apply Ridge regression with random_state=42 with default penalty value on training set(X_train and y_train) and calculate the ùëÖ2 score on test_set (X_test and y_test). What is the correct score ( Upto 4 digits after decimal points)? [NAT]"],"metadata":{"id":"loebcvACChRC"}},{"cell_type":"markdown","source":["V1: 0.1445 (Range: 0.1410 - 0.1470)"],"metadata":{"id":"sCU0RrgcC15U"}},{"cell_type":"markdown","source":["Q20: [Marks 6] Apply Lasso regression with random_state=42 and regularization rate=0.1 on the training data(X_train & y_train). Enter the value of the intercept you got correctly upto 2 digits after decimal points . [NAT]"],"metadata":{"id":"N9QIa6EeC3Jq"}},{"cell_type":"markdown","source":["Q21 [Marks 5] Fit SGDRegressor(random_state=42) estimator on the training data(X_train & y_train) and predict labels for test_data(X_test), lets call it as y_test_predict. The parameters are initialized with default values. Calculate and mark the correct mean_absolute_error value between y_test and y_test_predict from the given options. (Correct upto two decimals) [NAT]"],"metadata":{"id":"J4_mFxz9C6pw"}},{"cell_type":"markdown","source":["V1: 52840.14 (Range: 52800 - 52880)"],"metadata":{"id":"1sZuGKgeDX8y"}},{"cell_type":"markdown","source":["Q22: [Marks 6] Using SGDRegressor(random_state=42) as an estimator for exactly 10 iterations. Write the correct R2 score on test data  [NAT] (correct Upto 4 digits)"],"metadata":{"id":"GES5xq7EDe44"}},{"cell_type":"markdown","source":["V1: 0.1421 (Range: 0.1390 - 0.1450)"],"metadata":{"id":"i4VnQ5YsDswP"}},{"cell_type":"markdown","source":["# (Common Instructions for Question 23 and 24)\n","\n","##Create a pipeline Using PolynomialFeatures as transformer and Lasso as estimator. Use GridSearchCV with this created pipeline and following hyperparameter values on training data(X_train, y_train) to fit the model .\n","\n","1. Keep polynomial degree as : [1, 2]\n","2. alpha value to be taken as : np.logspace(-3, 0, num=5)\n","3. scoring : neg_mean_absolute_error .\n","\n","(Note: Kindly ignore the warning.)"],"metadata":{"id":"6lNBabDYD1Fy"}},{"cell_type":"markdown","source":["## Q23 [6 Marks] Mark the best `alpha` value you got using above instructions.[MCQ]\n","\n","A) 0.001\n","\n","B) 0.00562341\n","\n","C) 0.03162278\n","\n","D) 0.17782794\n","\n","E) 1.00\n","\n"],"metadata":{"id":"-sCZPRKVD3cq"}},{"cell_type":"code","source":[],"metadata":{"id":"A6YNYT_v7mTw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Q24 [5 Marks] Enter the best polynomial degree value you got using above instructions.[NAT]\n","\n","\n"],"metadata":{"id":"0r0QpGCiD6hF"}},{"cell_type":"code","source":[],"metadata":{"id":"wZqECZS37oSv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# (Common Instructions for Question 25 and 26)\n","## To Reduce number of dimensions of training data with PCA. Fit the PCA model using following parameter values on training data.\n","\n","* n_components=5\n","* svd_solver='full'\n","* whiten=True\n","* random_state=42\n"],"metadata":{"id":"Gz9LuKuID_ee"}},{"cell_type":"markdown","source":["## Q25: [Marks 5] What is the sum of `explained_variance_ratio_` ? [NAT]"],"metadata":{"id":"todHG9ZCEDNu"}},{"cell_type":"markdown","source":["## Q26: [Marks 6] Use PCA transformed training data from earlier question and y_train to fit the `RidgeCV` estimator model having alpha value as [0.001,0.01,0.1,1]. Calculate the R2 score you got from the model for transformed test data(PCA transformed X_test). [NAT] (upto 4 decimal)"],"metadata":{"id":"sjU6lefHEHHY"}}]}